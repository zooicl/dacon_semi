{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:44.678658Z",
     "start_time": "2020-01-16T02:57:43.515731Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[1]:\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "import glob\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import gc\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import json\n",
    "from typing import NamedTuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "print(torch.__version__)\n",
    "# from tools import eval_summary, save_feature_importance, merge_preds\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:44.681707Z",
     "start_time": "2020-01-16T02:57:44.679921Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_num_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:44.698790Z",
     "start_time": "2020-01-16T02:57:44.682940Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:56.530967Z",
     "start_time": "2020-01-16T02:57:44.700356Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('input/train.csv', dtype=np.float32)\n",
    "df_test = pd.read_csv('input/test.csv', dtype=np.float32)\n",
    "print(df_train.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T04:19:00.592001Z",
     "start_time": "2020-01-16T04:19:00.587169Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_cols = [c for c in df_train.columns if 'layer_' in c]\n",
    "fea_cols = [c for c in df_train.columns if c not in layer_cols]\n",
    "\n",
    "len(fea_cols), len(layer_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:56.552298Z",
     "start_time": "2020-01-16T02:57:56.535277Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:56.558263Z",
     "start_time": "2020-01-16T02:57:56.553011Z"
    }
   },
   "outputs": [],
   "source": [
    "class DNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout_probability=0.3):\n",
    "        super(DNNModel,self).__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(input_size, 4),\n",
    "#             torch.nn.Linear(input_size, 1),\n",
    "            torch.nn.Linear(input_size, 200), relu, torch.nn.BatchNorm1d(200), dropout, \n",
    "            torch.nn.Linear(200, 150), relu, torch.nn.BatchNorm1d(150), dropout,\n",
    "            torch.nn.Linear(150, 100), relu, torch.nn.BatchNorm1d(100), dropout,            \n",
    "            torch.nn.Linear(100, 64), relu, torch.nn.BatchNorm1d(64), dropout,\n",
    "            torch.nn.Linear(64, 32), relu, torch.nn.BatchNorm1d(32), dropout,            \n",
    "            torch.nn.Linear(32, 4)\n",
    "                           )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:56.565050Z",
     "start_time": "2020-01-16T02:57:56.558975Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_probability=0.3):\n",
    "        super().__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(1, 2, 31, stride=1, padding=0), #196\n",
    "            relu, torch.nn.MaxPool1d(2), #98 \n",
    "            torch.nn.Conv1d(2, 4, 19, stride=1, padding=0), #80\n",
    "            relu, torch.nn.MaxPool1d(2), #40\n",
    "            torch.nn.Conv1d(4, 8, 11, stride=1, padding=0), #30\n",
    "            relu, torch.nn.MaxPool1d(2), #15\n",
    "            torch.nn.Conv1d(8, 16, 6, stride=1, padding=1), #12\n",
    "            relu, torch.nn.MaxPool1d(2), #6\n",
    "        )\n",
    "            \n",
    "# #             torch.nn.Linear(input_size, 4),\n",
    "#             torch.nn.Linear(input_size, 200), relu, #torch.nn.BatchNorm1d(200), dropout, \n",
    "#             torch.nn.Linear(200, 200), relu, #torch.nn.BatchNorm1d(200), dropout,\n",
    "#             torch.nn.Linear(200, 200), relu, #torch.nn.BatchNorm1d(200), dropout,\n",
    "#             torch.nn.Linear(200, 150), relu, #torch.nn.BatchNorm1d(200), dropout,\n",
    "#             torch.nn.Linear(150, 128), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(128, 128), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(128, 100), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(100, 64), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(64, 32), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(32, 16), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(16, 8), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16*6, 64), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "            torch.nn.Linear(64, 4)\n",
    "       )\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out = self.cnn(x)\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]: #24, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:57:16.154252Z",
     "start_time": "2020-01-14T00:57:16.152105Z"
    }
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:58.002268Z",
     "start_time": "2020-01-16T02:57:56.566113Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print(model_ts)\n",
    "\n",
    "# layer_cols = [layer_cols[0]]\n",
    "\n",
    "print(f'fea_size {len(fea_cols)} layer_cols {layer_cols}')\n",
    "\n",
    "model = DNNModel(input_size=len(fea_cols), dropout_probability=0.5).to(device)\n",
    "# model = CNNModel(dropout_probability=0.5).to(device)\n",
    "    \n",
    "criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "scheduler = StepLR(optimizer, step_size=400, gamma=0.97)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:58.413658Z",
     "start_time": "2020-01-16T02:57:58.003300Z"
    }
   },
   "outputs": [],
   "source": [
    "X_batch = torch.Tensor(df_model[fea_cols].values).float().to(device)\n",
    "y_batch = torch.Tensor(df_model[layer_cols].values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T02:57:58.416135Z",
     "start_time": "2020-01-16T02:57:58.414618Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T04:18:43.922420Z",
     "start_time": "2020-01-16T02:57:58.416880Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_epoch = 5000\n",
    "model.train()\n",
    "\n",
    "for e in tqdm_notebook(range(total_epoch), total=total_epoch, desc='Epoch'):\n",
    "    y_pred = model(X_batch)\n",
    "    \n",
    "#     print(y_pred, y_batch)\n",
    "\n",
    "    loss = criterion(y_pred, y_batch)\n",
    "    print(f'Epock {e} / {total_epoch} loss: {loss.item()}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if e % 1000 == 0:\n",
    "        torch.save(model.state_dict(), 'checkpoint_1nn.pt')\n",
    "\n",
    "torch.save(model.state_dict(), 'checkpoint_1nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
