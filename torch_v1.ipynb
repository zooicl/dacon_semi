{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T09:45:32.676986Z",
     "start_time": "2020-01-16T09:45:31.989250Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiden/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n",
      "1.3.1\n",
      "GeForce RTX 2070 SUPER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[1]:\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "import glob\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import gc\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import json\n",
    "from typing import NamedTuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "print(torch.__version__)\n",
    "# from tools import eval_summary, save_feature_importance, merge_preds\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T09:45:32.680531Z",
     "start_time": "2020-01-16T09:45:32.678161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[2]:\n",
    "torch.set_num_threads(8)\n",
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T09:45:44.260220Z",
     "start_time": "2020-01-16T09:45:32.681613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810000, 230) (10000, 227)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('input/train.csv', dtype=np.float32)\n",
    "df_test = pd.read_csv('input/test.csv', dtype=np.float32)\n",
    "print(df_train.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T09:45:44.267997Z",
     "start_time": "2020-01-16T09:45:44.261273Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('input/SiO2.txt', sep='\\t')\n",
    "df2 = pd.read_csv('input/Si3N4.txt', sep='\\t')\n",
    "\n",
    "df_nk = pd.merge(df1, df2, on='Wavelength(nm)')\n",
    "df_nk = df_nk[:226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T09:45:44.277947Z",
     "start_time": "2020-01-16T09:45:44.268664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Wavelength(nm)', 'n_x', 'k_x', 'n_y', 'k_y'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:00:29.101376Z",
     "start_time": "2020-01-16T10:00:29.093979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5384, 1.5285, 1.5202, 1.5133, 1.5074, 1.5024, 1.498 , 1.4942,\n",
       "        1.4908, 1.4878, 1.4851, 1.4827, 1.4806, 1.4787, 1.4769, 1.4753,\n",
       "        1.4738, 1.4725, 1.4713, 1.4701, 1.4691, 1.4681, 1.4672, 1.4663,\n",
       "        1.4656, 1.4648, 1.4641, 1.4635, 1.4629, 1.4623, 1.4618, 1.4613,\n",
       "        1.4608, 1.4603, 1.4599, 1.4595, 1.4591, 1.4587, 1.4584, 1.458 ,\n",
       "        1.4577, 1.4574, 1.4571, 1.4568, 1.4565, 1.4563, 1.456 , 1.4558,\n",
       "        1.4555, 1.4553, 1.4551, 1.4549, 1.4546, 1.4544, 1.4542, 1.454 ,\n",
       "        1.4539, 1.4537, 1.4535, 1.4533, 1.4531, 1.453 , 1.4528, 1.4527,\n",
       "        1.4525, 1.4523, 1.4522, 1.452 , 1.4519, 1.4518, 1.4516, 1.4515,\n",
       "        1.4513, 1.4512, 1.4511, 1.4509, 1.4508, 1.4507, 1.4505, 1.4504,\n",
       "        1.4503, 1.4502, 1.45  , 1.4499, 1.4498, 1.4497, 1.4496, 1.4494,\n",
       "        1.4493, 1.4492, 1.4491, 1.449 , 1.4489, 1.4487, 1.4486, 1.4485,\n",
       "        1.4484, 1.4483, 1.4482, 1.4481, 1.4479, 1.4478, 1.4477, 1.4476,\n",
       "        1.4475, 1.4474, 1.4473, 1.4471, 1.447 , 1.4469, 1.4468, 1.4467,\n",
       "        1.4466, 1.4465, 1.4464, 1.4462, 1.4461, 1.446 , 1.4459, 1.4458,\n",
       "        1.4457, 1.4455, 1.4454, 1.4453, 1.4452, 1.4451, 1.445 , 1.4449,\n",
       "        1.4447, 1.4446, 1.4445, 1.4444, 1.4443, 1.4441, 1.444 , 1.4439,\n",
       "        1.4438, 1.4437, 1.4435, 1.4434, 1.4433, 1.4432, 1.4431, 1.4429,\n",
       "        1.4428, 1.4427, 1.4426, 1.4424, 1.4423, 1.4422, 1.442 , 1.4419,\n",
       "        1.4418, 1.4417, 1.4415, 1.4414, 1.4413, 1.4411, 1.441 , 1.4409,\n",
       "        1.4407, 1.4406, 1.4405, 1.4403, 1.4402, 1.4401, 1.4399, 1.4398,\n",
       "        1.4397, 1.4395, 1.4394, 1.4392, 1.4391, 1.4389, 1.4388, 1.4387,\n",
       "        1.4385, 1.4384, 1.4382, 1.4381, 1.4379, 1.4378, 1.4376, 1.4375,\n",
       "        1.4373, 1.4372, 1.437 , 1.4369, 1.4367, 1.4366, 1.4364, 1.4363,\n",
       "        1.4361, 1.436 , 1.4358, 1.4357, 1.4355, 1.4353, 1.4352, 1.435 ,\n",
       "        1.4349, 1.4347, 1.4345, 1.4344, 1.4342, 1.434 , 1.4339, 1.4337,\n",
       "        1.4335, 1.4334, 1.4332, 1.433 , 1.4328, 1.4327, 1.4325, 1.4323,\n",
       "        1.4322, 1.432 , 1.4318, 1.4316, 1.4314, 1.4313, 1.4311, 1.4309,\n",
       "        1.4307, 1.4305]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nk[['n_x']].T.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T09:45:44.284106Z",
     "start_time": "2020-01-16T09:45:44.278626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_cols = [c for c in df_train.columns if 'layer_' in c]\n",
    "fea_cols = [c for c in df_train.columns if c not in layer_cols]\n",
    "\n",
    "len(fea_cols), len(layer_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T09:45:44.291854Z",
     "start_time": "2020-01-16T09:45:44.285117Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T09:45:44.298023Z",
     "start_time": "2020-01-16T09:45:44.293064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size = 48\n",
    "W = 15 # input_volume_size\n",
    "F = 6  # kernel_size\n",
    "S = 1   # strides\n",
    "P = 1\n",
    "# padding_size\n",
    "\n",
    "size = (W - F + 2*P) / S + 1\n",
    "size\n",
    "# ((size - 1) * S) - 2*P + F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:00:51.745732Z",
     "start_time": "2020-01-16T10:00:51.730485Z"
    }
   },
   "outputs": [],
   "source": [
    "class DNN1Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout_probability=0.3):\n",
    "        super().__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.layer_1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "        )\n",
    "        self.layer_2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "        )\n",
    "        self.layer_3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "        )\n",
    "        self.layer_4 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "            torch.nn.Linear(input_size, input_size), relu, torch.nn.BatchNorm1d(input_size), dropout, \n",
    "        )\n",
    "        \n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, input_size), relu,\n",
    "            torch.nn.Linear(input_size, input_size), relu,\n",
    "            torch.nn.Linear(input_size, input_size), relu,\n",
    "            torch.nn.Linear(input_size, 4),\n",
    "        )\n",
    "        \n",
    "        self.layer13_n = torch.Tensor(df_nk[['n_x']].T.values).to(device)\n",
    "        self.layer13_k = torch.Tensor(df_nk[['k_x']].T.values).to(device)\n",
    "        self.layer24_n = torch.Tensor(df_nk[['n_y']].T.values).to(device)\n",
    "        self.layer24_k = torch.Tensor(df_nk[['k_y']].T.values).to(device)\n",
    "        \n",
    "    \n",
    "    def forward(self, x_fea):\n",
    "        \n",
    "        out_layer_1 = self.layer_1(torch.add(torch.mul(x_fea, self.layer13_n), self.layer13_k))\n",
    "        out_layer_2 = self.layer_2(torch.add(torch.mul(out_layer_1, self.layer24_n), self.layer24_k))\n",
    "        out_layer_3 = self.layer_3(torch.add(torch.mul(out_layer_2, self.layer13_n), self.layer13_k))\n",
    "        out_layer_4 = self.layer_4(torch.add(torch.mul(out_layer_2, self.layer24_n), self.layer24_k))\n",
    "        \n",
    "        return self.fc(out_layer_4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:00:51.913481Z",
     "start_time": "2020-01-16T10:00:51.898491Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_probability=0.3):\n",
    "        super().__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(1, 2, 31, stride=1, padding=0), #196\n",
    "            relu, torch.nn.MaxPool1d(2), #98 \n",
    "            torch.nn.Conv1d(2, 4, 19, stride=1, padding=0), #80\n",
    "            relu, torch.nn.MaxPool1d(2), #40\n",
    "            torch.nn.Conv1d(4, 8, 11, stride=1, padding=0), #30\n",
    "            relu, torch.nn.MaxPool1d(2), #15\n",
    "            torch.nn.Conv1d(8, 16, 6, stride=1, padding=1), #12\n",
    "            relu, torch.nn.MaxPool1d(2), #6\n",
    "        )\n",
    "            \n",
    "# #             torch.nn.Linear(input_size, 4),\n",
    "#             torch.nn.Linear(input_size, 200), relu, #torch.nn.BatchNorm1d(200), dropout, \n",
    "#             torch.nn.Linear(200, 200), relu, #torch.nn.BatchNorm1d(200), dropout,\n",
    "#             torch.nn.Linear(200, 200), relu, #torch.nn.BatchNorm1d(200), dropout,\n",
    "#             torch.nn.Linear(200, 150), relu, #torch.nn.BatchNorm1d(200), dropout,\n",
    "#             torch.nn.Linear(150, 128), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(128, 128), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(128, 100), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(100, 64), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(64, 32), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(32, 16), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "#             torch.nn.Linear(16, 8), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16*6, 64), relu, #torch.nn.BatchNorm1d(128), dropout,\n",
    "            torch.nn.Linear(64, 4)\n",
    "       )\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out = self.cnn(x)\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]: #24, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "        return self.model(x)\n",
    "    \n",
    "class DNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout_probability=0.3):\n",
    "        super(DNNModel,self).__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(input_size, 4),\n",
    "#             torch.nn.Linear(input_size, 1),\n",
    "            torch.nn.Linear(input_size, 200), relu, torch.nn.BatchNorm1d(200), dropout, \n",
    "            torch.nn.Linear(200, 150), relu, torch.nn.BatchNorm1d(150), dropout,\n",
    "            torch.nn.Linear(150, 100), relu, torch.nn.BatchNorm1d(100), dropout,            \n",
    "            torch.nn.Linear(100, 64), relu, torch.nn.BatchNorm1d(64), dropout,\n",
    "            torch.nn.Linear(64, 32), relu, torch.nn.BatchNorm1d(32), dropout,            \n",
    "            torch.nn.Linear(32, 4)\n",
    "                           )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class SemiDataset(Dataset):\n",
    "    def __init__(self, df, fea_cols, y_cols):        \n",
    "        self.X = df[fea_cols].values\n",
    "        self.y = df[y_cols].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].astype(np.float32), self.y[idx].astype(np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:00:52.203300Z",
     "start_time": "2020-01-16T10:00:52.191943Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, criterion, optimizer, scheduler, device):\n",
    "        self.device = device\n",
    "        self.model = model#.to(self.device)\n",
    "        self.criterion = criterion#.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        print(self.model.train())\n",
    "        pass\n",
    "    \n",
    "    def train(self, data_loader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "#         print('train_loader', len(train_loader))\n",
    "        for data in data_loader:\n",
    "            X_batch, y_batch = data\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            \n",
    "            y_pred = self.model(X_batch)\n",
    "#             print(y_pred, y_batch)\n",
    "            \n",
    "            loss = self.criterion(y_pred, y_batch)\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "#         print(f'total_loss {total_loss / len(data_loader)}')\n",
    "        return total_loss / len(data_loader)\n",
    "    \n",
    "    def eval(self, data_loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "#         print('valid_loader', len(valid_loader))\n",
    "        for data in data_loader:\n",
    "            X_batch, y_batch = data\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                y_pred = self.model(X_batch)\n",
    "                loss = self.criterion(y_pred, y_batch)\n",
    "                print(y_pred, y_batch)\n",
    "#                 print(loss.item())\n",
    "                total_loss = total_loss + loss.item()\n",
    "#         print(f'total_loss {total_loss / len(data_loader)}')\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def save(self, model_path='checkpoint.pt'):\n",
    "        torch.save(self.model.state_dict(), 'checkpoint.pt')\n",
    "        return\n",
    "    \n",
    "    def load(self, model_path='checkpoint.pt'):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:57:16.154252Z",
     "start_time": "2020-01-14T00:57:16.152105Z"
    }
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:00:52.776821Z",
     "start_time": "2020-01-16T10:00:52.472859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200116T190052\n",
      "batch_size 10000 num_workers 0\n",
      "fea_size 226 layer_cols ['layer_1', 'layer_2', 'layer_3', 'layer_4']\n",
      "DNN1Model(\n",
      "  (layer_1): Sequential(\n",
      "    (0): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (layer_2): Sequential(\n",
      "    (0): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (layer_3): Sequential(\n",
      "    (0): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (layer_4): Sequential(\n",
      "    (0): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm1d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=226, out_features=226, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=226, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "train_loader 81\n"
     ]
    }
   ],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print(model_ts)\n",
    "\n",
    "batch_size = 10000\n",
    "num_workers = 0\n",
    "\n",
    "print(f'batch_size {batch_size} num_workers {num_workers}')\n",
    "print(f'fea_size {len(fea_cols)} layer_cols {layer_cols}')\n",
    "\n",
    "\n",
    "model = DNN1Model(input_size=len(fea_cols), dropout_probability=0.5).to(device)\n",
    "#     model = CNNModel(dropout_probability=0.1).to(device)\n",
    "\n",
    "    \n",
    "criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "# criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=400, gamma=0.97)\n",
    "\n",
    "trainer = Trainer(model, criterion, optimizer, scheduler, device)\n",
    "# trainer.load()\n",
    "\n",
    "train_dataset = SemiDataset(df_model[fea_cols + layer_cols], fea_cols, layer_cols)\n",
    "\n",
    "train_loader_params = {\n",
    "    'dataset' : train_dataset,\n",
    "    'batch_size' : batch_size,\n",
    "    'shuffle' : False,\n",
    "    'num_workers' : num_workers,\n",
    "    'drop_last' : False,\n",
    "}\n",
    "train_loader = DataLoader(**train_loader_params)\n",
    "\n",
    "print(f'train_loader {len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:00:52.779006Z",
     "start_time": "2020-01-16T10:00:52.777649Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-16T10:00:52.819Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78abc45d52344daa39821fcd8c458b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1000, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200116T190101] Epock 0 / 1000 loss: 78.78073454491886\n",
      "[20200116T190111] Epock 1 / 1000 loss: 70.00115914992344\n",
      "[20200116T190120] Epock 2 / 1000 loss: 69.00374363086841\n",
      "[20200116T190129] Epock 3 / 1000 loss: 67.31920623779297\n",
      "[20200116T190138] Epock 4 / 1000 loss: 62.18537177568601\n",
      "[20200116T190148] Epock 5 / 1000 loss: 61.07716991283275\n",
      "[20200116T190157] Epock 6 / 1000 loss: 61.415932031325355\n",
      "[20200116T190206] Epock 7 / 1000 loss: 61.62692025267047\n",
      "[20200116T190215] Epock 8 / 1000 loss: 61.63267540637358\n",
      "[20200116T190224] Epock 9 / 1000 loss: 61.54740500744478\n",
      "[20200116T190233] Epock 10 / 1000 loss: 61.8875867113655\n",
      "[20200116T190242] Epock 11 / 1000 loss: 61.84366113168222\n",
      "[20200116T190251] Epock 12 / 1000 loss: 62.20671599588277\n",
      "[20200116T190301] Epock 13 / 1000 loss: 62.16505973721728\n",
      "[20200116T190310] Epock 14 / 1000 loss: 61.37394827383536\n",
      "[20200116T190319] Epock 15 / 1000 loss: 61.57396076343678\n",
      "[20200116T190328] Epock 16 / 1000 loss: 62.08176247867537\n",
      "[20200116T190337] Epock 17 / 1000 loss: 61.505721857518324\n",
      "[20200116T190347] Epock 18 / 1000 loss: 60.74727428106614\n",
      "[20200116T190356] Epock 19 / 1000 loss: 60.41141123830536\n",
      "[20200116T190405] Epock 20 / 1000 loss: 61.594377070297426\n",
      "[20200116T190414] Epock 21 / 1000 loss: 61.97584453629859\n",
      "[20200116T190423] Epock 22 / 1000 loss: 62.16528141351394\n",
      "[20200116T190433] Epock 23 / 1000 loss: 62.38363350762261\n",
      "[20200116T190442] Epock 24 / 1000 loss: 62.011894367359304\n",
      "[20200116T190451] Epock 25 / 1000 loss: 62.19009606632186\n",
      "[20200116T190500] Epock 26 / 1000 loss: 62.35345642654984\n",
      "[20200116T190509] Epock 27 / 1000 loss: 62.32639322163146\n",
      "[20200116T190519] Epock 28 / 1000 loss: 62.28164526856976\n",
      "[20200116T190528] Epock 29 / 1000 loss: 62.270002859610095\n",
      "[20200116T190537] Epock 30 / 1000 loss: 61.88277581297321\n",
      "[20200116T190546] Epock 31 / 1000 loss: 62.065370347764755\n",
      "[20200116T190555] Epock 32 / 1000 loss: 61.82889170705536\n",
      "[20200116T190604] Epock 33 / 1000 loss: 60.588476251672816\n",
      "[20200116T190613] Epock 34 / 1000 loss: 61.18557654486762\n",
      "[20200116T190622] Epock 35 / 1000 loss: 59.265309274932484\n",
      "[20200116T190631] Epock 36 / 1000 loss: 57.73425387158806\n",
      "[20200116T190639] Epock 37 / 1000 loss: 58.614460038550106\n",
      "[20200116T190648] Epock 38 / 1000 loss: 58.44629838731554\n",
      "[20200116T190657] Epock 39 / 1000 loss: 57.81410431567534\n",
      "[20200116T190705] Epock 40 / 1000 loss: 56.817350623048384\n",
      "[20200116T190714] Epock 41 / 1000 loss: 55.07975170936113\n",
      "[20200116T190723] Epock 42 / 1000 loss: 53.11524198084702\n",
      "[20200116T190732] Epock 43 / 1000 loss: 55.16100075804157\n",
      "[20200116T190741] Epock 44 / 1000 loss: 56.77382123028791\n",
      "[20200116T190750] Epock 45 / 1000 loss: 56.11553950368622\n",
      "[20200116T190759] Epock 46 / 1000 loss: 55.27789424378195\n",
      "[20200116T190809] Epock 47 / 1000 loss: 56.05189973336679\n",
      "[20200116T190818] Epock 48 / 1000 loss: 56.686034355634526\n",
      "[20200116T190827] Epock 49 / 1000 loss: 56.620161056518555\n",
      "[20200116T190836] Epock 50 / 1000 loss: 56.648622983767666\n",
      "[20200116T190845] Epock 51 / 1000 loss: 56.552507942105514\n",
      "[20200116T190854] Epock 52 / 1000 loss: 56.44075275939188\n",
      "[20200116T190903] Epock 53 / 1000 loss: 56.34925799899631\n",
      "[20200116T190913] Epock 54 / 1000 loss: 55.32590519940412\n",
      "[20200116T190922] Epock 55 / 1000 loss: 54.57188413172592\n",
      "[20200116T190931] Epock 56 / 1000 loss: 55.141118697178214\n",
      "[20200116T190940] Epock 57 / 1000 loss: 55.99677837042161\n",
      "[20200116T190949] Epock 58 / 1000 loss: 56.001172995861666\n",
      "[20200116T190959] Epock 59 / 1000 loss: 55.92495103529942\n",
      "[20200116T191008] Epock 60 / 1000 loss: 55.944135548155984\n",
      "[20200116T191017] Epock 61 / 1000 loss: 55.30306726620521\n",
      "[20200116T191026] Epock 62 / 1000 loss: 54.528331403379084\n",
      "[20200116T191035] Epock 63 / 1000 loss: 54.74468078142331\n",
      "[20200116T191044] Epock 64 / 1000 loss: 53.678543820793244\n",
      "[20200116T191053] Epock 65 / 1000 loss: 53.8635173138277\n",
      "[20200116T191102] Epock 66 / 1000 loss: 55.329916471316494\n",
      "[20200116T191112] Epock 67 / 1000 loss: 55.64783626132541\n",
      "[20200116T191121] Epock 68 / 1000 loss: 55.56120429804296\n",
      "[20200116T191130] Epock 69 / 1000 loss: 55.62596304622697\n",
      "[20200116T191139] Epock 70 / 1000 loss: 55.56819918126236\n",
      "[20200116T191147] Epock 71 / 1000 loss: 55.62326928126959\n",
      "[20200116T191156] Epock 72 / 1000 loss: 55.58183698300962\n",
      "[20200116T191205] Epock 73 / 1000 loss: 55.425992706675586\n",
      "[20200116T191214] Epock 74 / 1000 loss: 55.53537439416956\n",
      "[20200116T191224] Epock 75 / 1000 loss: 55.61116350432973\n",
      "[20200116T191233] Epock 76 / 1000 loss: 56.07005769235116\n",
      "[20200116T191242] Epock 77 / 1000 loss: 55.86814404711311\n",
      "[20200116T191251] Epock 78 / 1000 loss: 56.04236591009446\n",
      "[20200116T191301] Epock 79 / 1000 loss: 55.62127155727811\n",
      "[20200116T191310] Epock 80 / 1000 loss: 56.315647643289445\n",
      "[20200116T191319] Epock 81 / 1000 loss: 56.059145939202956\n",
      "[20200116T191328] Epock 82 / 1000 loss: 55.58668334395797\n",
      "[20200116T191337] Epock 83 / 1000 loss: 55.292610027171946\n",
      "[20200116T191346] Epock 84 / 1000 loss: 56.43734898979281\n",
      "[20200116T191354] Epock 85 / 1000 loss: 55.46326133351267\n",
      "[20200116T191403] Epock 86 / 1000 loss: 55.22348453380443\n",
      "[20200116T191412] Epock 87 / 1000 loss: 55.112557305230034\n",
      "[20200116T191421] Epock 88 / 1000 loss: 55.16606797112359\n",
      "[20200116T191430] Epock 89 / 1000 loss: 55.281281742048854\n",
      "[20200116T191440] Epock 90 / 1000 loss: 54.9773912312072\n",
      "[20200116T191449] Epock 91 / 1000 loss: 54.96044118904773\n",
      "[20200116T191458] Epock 92 / 1000 loss: 54.80332565307617\n",
      "[20200116T191507] Epock 93 / 1000 loss: 54.864693936006525\n",
      "[20200116T191517] Epock 94 / 1000 loss: 54.81908494454843\n",
      "[20200116T191526] Epock 95 / 1000 loss: 54.6540022249575\n",
      "[20200116T191535] Epock 96 / 1000 loss: 54.741871068507066\n",
      "[20200116T191544] Epock 97 / 1000 loss: 54.42979183903447\n",
      "[20200116T191553] Epock 98 / 1000 loss: 54.53320651584201\n",
      "[20200116T191602] Epock 99 / 1000 loss: 54.36050332622764\n",
      "[20200116T191611] Epock 100 / 1000 loss: 54.68368586787471\n",
      "[20200116T191620] Epock 101 / 1000 loss: 54.75300845393428\n",
      "[20200116T191628] Epock 102 / 1000 loss: 54.301081786920996\n",
      "[20200116T191637] Epock 103 / 1000 loss: 54.407217072851864\n",
      "[20200116T191646] Epock 104 / 1000 loss: 54.46471150716146\n",
      "[20200116T191655] Epock 105 / 1000 loss: 54.16918674516089\n",
      "[20200116T191705] Epock 106 / 1000 loss: 54.05666031072169\n",
      "[20200116T191714] Epock 107 / 1000 loss: 54.33081245422363\n",
      "[20200116T191723] Epock 108 / 1000 loss: 54.00858704837752\n",
      "[20200116T191732] Epock 109 / 1000 loss: 54.15191655100128\n",
      "[20200116T191742] Epock 110 / 1000 loss: 53.94734785291884\n",
      "[20200116T191751] Epock 111 / 1000 loss: 54.09835299739131\n",
      "[20200116T191800] Epock 112 / 1000 loss: 54.334152598439914\n",
      "[20200116T191809] Epock 113 / 1000 loss: 53.863170388304155\n",
      "[20200116T191818] Epock 114 / 1000 loss: 54.130630398974006\n",
      "[20200116T191827] Epock 115 / 1000 loss: 54.24035390218099\n",
      "[20200116T191836] Epock 116 / 1000 loss: 54.026032836348925\n",
      "[20200116T191846] Epock 117 / 1000 loss: 53.890907005027486\n",
      "[20200116T191855] Epock 118 / 1000 loss: 54.83249282836914\n",
      "[20200116T191904] Epock 119 / 1000 loss: 54.360965493284624\n",
      "[20200116T191913] Epock 120 / 1000 loss: 53.650271474579235\n",
      "[20200116T191922] Epock 121 / 1000 loss: 53.07812817891439\n",
      "[20200116T191931] Epock 122 / 1000 loss: 52.61224494745702\n",
      "[20200116T191941] Epock 123 / 1000 loss: 53.07232814364963\n",
      "[20200116T191950] Epock 124 / 1000 loss: 53.462715949541256\n",
      "[20200116T191959] Epock 125 / 1000 loss: 53.1274348364936\n",
      "[20200116T192008] Epock 126 / 1000 loss: 52.75591890311536\n",
      "[20200116T192017] Epock 127 / 1000 loss: 53.49747770803946\n",
      "[20200116T192027] Epock 128 / 1000 loss: 52.96528931605963\n",
      "[20200116T192036] Epock 129 / 1000 loss: 53.40968859637225\n",
      "[20200116T192045] Epock 130 / 1000 loss: 52.878994576724956\n",
      "[20200116T192054] Epock 131 / 1000 loss: 52.88112678056882\n",
      "[20200116T192104] Epock 132 / 1000 loss: 53.39017505410277\n",
      "[20200116T192113] Epock 133 / 1000 loss: 52.87992536285777\n",
      "[20200116T192122] Epock 134 / 1000 loss: 52.605276602285876\n",
      "[20200116T192131] Epock 135 / 1000 loss: 52.05344503897208\n",
      "[20200116T192141] Epock 136 / 1000 loss: 50.30463925114385\n",
      "[20200116T192150] Epock 137 / 1000 loss: 51.11228815714518\n",
      "[20200116T192159] Epock 138 / 1000 loss: 52.493520618956765\n",
      "[20200116T192208] Epock 139 / 1000 loss: 53.50557765254268\n",
      "[20200116T192217] Epock 140 / 1000 loss: 53.09018427059974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200116T192226] Epock 141 / 1000 loss: 52.96659716853389\n",
      "[20200116T192236] Epock 142 / 1000 loss: 51.41338310712649\n",
      "[20200116T192245] Epock 143 / 1000 loss: 48.59644176341869\n",
      "[20200116T192254] Epock 144 / 1000 loss: 47.499957473189745\n",
      "[20200116T192303] Epock 145 / 1000 loss: 47.68413461284873\n",
      "[20200116T192312] Epock 146 / 1000 loss: 49.526657975750204\n",
      "[20200116T192322] Epock 147 / 1000 loss: 49.54823190194589\n",
      "[20200116T192331] Epock 148 / 1000 loss: 48.80183971075364\n",
      "[20200116T192340] Epock 149 / 1000 loss: 47.92830066916383\n",
      "[20200116T192349] Epock 150 / 1000 loss: 46.87087026054476\n",
      "[20200116T192359] Epock 151 / 1000 loss: 46.85523527639884\n",
      "[20200116T192408] Epock 152 / 1000 loss: 45.886754659958825\n",
      "[20200116T192417] Epock 153 / 1000 loss: 45.24894848576299\n",
      "[20200116T192426] Epock 154 / 1000 loss: 44.65244406240958\n",
      "[20200116T192436] Epock 155 / 1000 loss: 44.636208027969175\n",
      "[20200116T192445] Epock 156 / 1000 loss: 44.55177099910783\n",
      "[20200116T192454] Epock 157 / 1000 loss: 44.02126856203432\n",
      "[20200116T192503] Epock 158 / 1000 loss: 45.058963940467365\n",
      "[20200116T192512] Epock 159 / 1000 loss: 45.456849722214685\n",
      "[20200116T192522] Epock 160 / 1000 loss: 44.212423183299876\n",
      "[20200116T192531] Epock 161 / 1000 loss: 44.281144930992596\n",
      "[20200116T192540] Epock 162 / 1000 loss: 43.56337862838934\n",
      "[20200116T192549] Epock 163 / 1000 loss: 43.9817472151768\n",
      "[20200116T192559] Epock 164 / 1000 loss: 43.564257704181436\n",
      "[20200116T192608] Epock 165 / 1000 loss: 43.26477801946946\n",
      "[20200116T192617] Epock 166 / 1000 loss: 43.55181769382806\n",
      "[20200116T192626] Epock 167 / 1000 loss: 43.53638724338861\n",
      "[20200116T192636] Epock 168 / 1000 loss: 43.36017330781913\n",
      "[20200116T192645] Epock 169 / 1000 loss: 42.84502500369225\n",
      "[20200116T192654] Epock 170 / 1000 loss: 41.954387688342436\n",
      "[20200116T192703] Epock 171 / 1000 loss: 42.714399008103356\n",
      "[20200116T192712] Epock 172 / 1000 loss: 42.796648472915464\n",
      "[20200116T192722] Epock 173 / 1000 loss: 42.8121457511996\n",
      "[20200116T192731] Epock 174 / 1000 loss: 42.7316076255139\n",
      "[20200116T192740] Epock 175 / 1000 loss: 42.81857718950437\n",
      "[20200116T192749] Epock 176 / 1000 loss: 42.528098777488424\n",
      "[20200116T192759] Epock 177 / 1000 loss: 42.71016368159541\n",
      "[20200116T192808] Epock 178 / 1000 loss: 42.44572655948592\n",
      "[20200116T192817] Epock 179 / 1000 loss: 42.64156044854058\n",
      "[20200116T192826] Epock 180 / 1000 loss: 43.28532607467086\n",
      "[20200116T192834] Epock 181 / 1000 loss: 42.71357413868845\n",
      "[20200116T192843] Epock 182 / 1000 loss: 42.79651907932611\n",
      "[20200116T192852] Epock 183 / 1000 loss: 42.698068171371645\n",
      "[20200116T192901] Epock 184 / 1000 loss: 43.38703139034318\n",
      "[20200116T192909] Epock 185 / 1000 loss: 42.10491872716833\n",
      "[20200116T192919] Epock 186 / 1000 loss: 41.978786444958345\n",
      "[20200116T192928] Epock 187 / 1000 loss: 42.63410518787526\n",
      "[20200116T192937] Epock 188 / 1000 loss: 42.355611377292206\n",
      "[20200116T192946] Epock 189 / 1000 loss: 42.340797871719175\n",
      "[20200116T192955] Epock 190 / 1000 loss: 43.06960277792848\n",
      "[20200116T193005] Epock 191 / 1000 loss: 42.345105606832625\n",
      "[20200116T193014] Epock 192 / 1000 loss: 41.364608411435725\n",
      "[20200116T193023] Epock 193 / 1000 loss: 41.610907754780335\n",
      "[20200116T193032] Epock 194 / 1000 loss: 41.493629455566406\n",
      "[20200116T193042] Epock 195 / 1000 loss: 41.48071088908631\n",
      "[20200116T193051] Epock 196 / 1000 loss: 43.46574441886243\n",
      "[20200116T193100] Epock 197 / 1000 loss: 45.73942923840181\n",
      "[20200116T193109] Epock 198 / 1000 loss: 44.59651132277501\n",
      "[20200116T193119] Epock 199 / 1000 loss: 42.91173600561825\n",
      "[20200116T193128] Epock 200 / 1000 loss: 42.96700011359321\n",
      "[20200116T193137] Epock 201 / 1000 loss: 42.95039645536446\n",
      "[20200116T193146] Epock 202 / 1000 loss: 42.38479032634217\n",
      "[20200116T193155] Epock 203 / 1000 loss: 42.28353031770683\n",
      "[20200116T193204] Epock 204 / 1000 loss: 41.67591262158052\n",
      "[20200116T193213] Epock 205 / 1000 loss: 41.34956607112178\n",
      "[20200116T193222] Epock 206 / 1000 loss: 41.62070012975622\n",
      "[20200116T193231] Epock 207 / 1000 loss: 41.472449408637154\n",
      "[20200116T193240] Epock 208 / 1000 loss: 41.908607694837784\n",
      "[20200116T193250] Epock 209 / 1000 loss: 42.64417276264709\n",
      "[20200116T193259] Epock 210 / 1000 loss: 42.76173850636423\n",
      "[20200116T193308] Epock 211 / 1000 loss: 42.829311794704864\n",
      "[20200116T193317] Epock 212 / 1000 loss: 42.18848157812048\n",
      "[20200116T193326] Epock 213 / 1000 loss: 42.85093411104179\n",
      "[20200116T193335] Epock 214 / 1000 loss: 42.88336614914882\n",
      "[20200116T193344] Epock 215 / 1000 loss: 43.99656613667806\n",
      "[20200116T193352] Epock 216 / 1000 loss: 41.7726988380338\n",
      "[20200116T193401] Epock 217 / 1000 loss: 43.982788344960156\n",
      "[20200116T193410] Epock 218 / 1000 loss: 42.23901404863523\n",
      "[20200116T193419] Epock 219 / 1000 loss: 44.68877309634362\n",
      "[20200116T193428] Epock 220 / 1000 loss: 42.83869265332634\n",
      "[20200116T193437] Epock 221 / 1000 loss: 43.27367448218075\n",
      "[20200116T193446] Epock 222 / 1000 loss: 45.39820014105903\n",
      "[20200116T193456] Epock 223 / 1000 loss: 43.3137094238658\n",
      "[20200116T193505] Epock 224 / 1000 loss: 42.12442727736485\n",
      "[20200116T193514] Epock 225 / 1000 loss: 43.84422003192666\n",
      "[20200116T193523] Epock 226 / 1000 loss: 43.178387488847896\n",
      "[20200116T193532] Epock 227 / 1000 loss: 41.98067533234019\n",
      "[20200116T193542] Epock 228 / 1000 loss: 42.19117951098784\n",
      "[20200116T193551] Epock 229 / 1000 loss: 42.317960409470544\n",
      "[20200116T193600] Epock 230 / 1000 loss: 42.393917366310404\n",
      "[20200116T193609] Epock 231 / 1000 loss: 41.953451015331126\n",
      "[20200116T193619] Epock 232 / 1000 loss: 41.9147299307364\n",
      "[20200116T193628] Epock 233 / 1000 loss: 40.430235285817844\n",
      "[20200116T193637] Epock 234 / 1000 loss: 41.08750943784361\n",
      "[20200116T193646] Epock 235 / 1000 loss: 43.7128018979673\n",
      "[20200116T193655] Epock 236 / 1000 loss: 42.002689079002096\n",
      "[20200116T193704] Epock 237 / 1000 loss: 41.01345742779014\n",
      "[20200116T193714] Epock 238 / 1000 loss: 42.359752089888964\n",
      "[20200116T193723] Epock 239 / 1000 loss: 40.78588316175673\n",
      "[20200116T193732] Epock 240 / 1000 loss: 40.38667695316268\n",
      "[20200116T193741] Epock 241 / 1000 loss: 40.950408158478915\n",
      "[20200116T193750] Epock 242 / 1000 loss: 40.84691497425974\n",
      "[20200116T193759] Epock 243 / 1000 loss: 40.98073408338759\n",
      "[20200116T193808] Epock 244 / 1000 loss: 41.59931192280334\n",
      "[20200116T193817] Epock 245 / 1000 loss: 42.442786040129484\n",
      "[20200116T193826] Epock 246 / 1000 loss: 41.87718367870943\n",
      "[20200116T193835] Epock 247 / 1000 loss: 41.03629199369454\n",
      "[20200116T193843] Epock 248 / 1000 loss: 41.15555056819209\n",
      "[20200116T193852] Epock 249 / 1000 loss: 40.93413030365367\n",
      "[20200116T193901] Epock 250 / 1000 loss: 40.501245710584854\n",
      "[20200116T193910] Epock 251 / 1000 loss: 40.73046206250603\n",
      "[20200116T193919] Epock 252 / 1000 loss: 40.072862648669584\n",
      "[20200116T193929] Epock 253 / 1000 loss: 39.934625531420295\n",
      "[20200116T193938] Epock 254 / 1000 loss: 40.13907927053946\n",
      "[20200116T193947] Epock 255 / 1000 loss: 40.386942168812695\n",
      "[20200116T193956] Epock 256 / 1000 loss: 40.38983910172074\n",
      "[20200116T194006] Epock 257 / 1000 loss: 39.9093588369864\n",
      "[20200116T194015] Epock 258 / 1000 loss: 38.62157028104052\n",
      "[20200116T194024] Epock 259 / 1000 loss: 39.52215036933805\n",
      "[20200116T194033] Epock 260 / 1000 loss: 38.79666434393989\n",
      "[20200116T194042] Epock 261 / 1000 loss: 39.37158794167601\n",
      "[20200116T194052] Epock 262 / 1000 loss: 39.362990226274654\n",
      "[20200116T194101] Epock 263 / 1000 loss: 39.1965097968961\n",
      "[20200116T194110] Epock 264 / 1000 loss: 39.571035926724655\n",
      "[20200116T194119] Epock 265 / 1000 loss: 39.38646504908432\n",
      "[20200116T194129] Epock 266 / 1000 loss: 38.5862511764338\n",
      "[20200116T194138] Epock 267 / 1000 loss: 39.61237299883807\n",
      "[20200116T194147] Epock 268 / 1000 loss: 39.156275125197425\n",
      "[20200116T194157] Epock 269 / 1000 loss: 39.54216599170073\n",
      "[20200116T194206] Epock 270 / 1000 loss: 38.192734353336284\n",
      "[20200116T194215] Epock 271 / 1000 loss: 39.16564644707574\n",
      "[20200116T194224] Epock 272 / 1000 loss: 38.904062671425905\n",
      "[20200116T194233] Epock 273 / 1000 loss: 38.96942847452046\n",
      "[20200116T194242] Epock 274 / 1000 loss: 39.03709197338716\n",
      "[20200116T194252] Epock 275 / 1000 loss: 38.496655216923465\n",
      "[20200116T194301] Epock 276 / 1000 loss: 38.705120392787606\n",
      "[20200116T194310] Epock 277 / 1000 loss: 39.13812166378822\n",
      "[20200116T194319] Epock 278 / 1000 loss: 38.356266186561115\n",
      "[20200116T194328] Epock 279 / 1000 loss: 37.9915648566352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200116T194337] Epock 280 / 1000 loss: 39.45002668875235\n",
      "[20200116T194347] Epock 281 / 1000 loss: 37.915724224514435\n",
      "[20200116T194356] Epock 282 / 1000 loss: 39.185834766905984\n",
      "[20200116T194405] Epock 283 / 1000 loss: 38.90020521187488\n",
      "[20200116T194414] Epock 284 / 1000 loss: 39.39622365692515\n",
      "[20200116T194424] Epock 285 / 1000 loss: 37.95409261444468\n",
      "[20200116T194433] Epock 286 / 1000 loss: 37.58830645054947\n",
      "[20200116T194442] Epock 287 / 1000 loss: 38.719272095480086\n",
      "[20200116T194451] Epock 288 / 1000 loss: 40.033114233134704\n",
      "[20200116T194501] Epock 289 / 1000 loss: 37.54919662004636\n",
      "[20200116T194510] Epock 290 / 1000 loss: 38.01658112325786\n",
      "[20200116T194519] Epock 291 / 1000 loss: 38.759935638050976\n",
      "[20200116T194528] Epock 292 / 1000 loss: 38.61010619740427\n",
      "[20200116T194537] Epock 293 / 1000 loss: 38.175812992048854\n",
      "[20200116T194546] Epock 294 / 1000 loss: 37.65456277352792\n",
      "[20200116T194556] Epock 295 / 1000 loss: 37.022842360131534\n",
      "[20200116T194605] Epock 296 / 1000 loss: 38.476646823647584\n",
      "[20200116T194614] Epock 297 / 1000 loss: 38.18567148844401\n",
      "[20200116T194623] Epock 298 / 1000 loss: 37.64397510481469\n",
      "[20200116T194633] Epock 299 / 1000 loss: 38.04588880656678\n",
      "[20200116T194642] Epock 300 / 1000 loss: 37.62152156123408\n",
      "[20200116T194651] Epock 301 / 1000 loss: 38.0398621029324\n",
      "[20200116T194700] Epock 302 / 1000 loss: 37.24334945207761\n",
      "[20200116T194709] Epock 303 / 1000 loss: 37.784804026285805\n",
      "[20200116T194719] Epock 304 / 1000 loss: 37.7791446638696\n",
      "[20200116T194728] Epock 305 / 1000 loss: 36.45094532436795\n",
      "[20200116T194737] Epock 306 / 1000 loss: 36.40330349957502\n",
      "[20200116T194746] Epock 307 / 1000 loss: 36.950411101918164\n",
      "[20200116T194756] Epock 308 / 1000 loss: 38.82418123881022\n",
      "[20200116T194805] Epock 309 / 1000 loss: 35.99758124645845\n",
      "[20200116T194814] Epock 310 / 1000 loss: 35.76076524051619\n",
      "[20200116T194823] Epock 311 / 1000 loss: 35.79812153474784\n",
      "[20200116T194833] Epock 312 / 1000 loss: 36.48799634862829\n",
      "[20200116T194842] Epock 313 / 1000 loss: 35.14130168490939\n",
      "[20200116T194851] Epock 314 / 1000 loss: 36.56492953830295\n",
      "[20200116T194900] Epock 315 / 1000 loss: 37.18974450193805\n",
      "[20200116T194910] Epock 316 / 1000 loss: 36.465484783973224\n",
      "[20200116T194919] Epock 317 / 1000 loss: 35.96574258215634\n",
      "[20200116T194928] Epock 318 / 1000 loss: 37.60019945215296\n",
      "[20200116T194937] Epock 319 / 1000 loss: 36.17150584562325\n",
      "[20200116T194947] Epock 320 / 1000 loss: 37.151403262291424\n",
      "[20200116T194956] Epock 321 / 1000 loss: 36.53591721146195\n",
      "[20200116T195005] Epock 322 / 1000 loss: 37.34367935745804\n",
      "[20200116T195014] Epock 323 / 1000 loss: 36.74160587640456\n",
      "[20200116T195024] Epock 324 / 1000 loss: 35.850081714583034\n",
      "[20200116T195033] Epock 325 / 1000 loss: 35.92524867587619\n",
      "[20200116T195042] Epock 326 / 1000 loss: 35.89707758397232\n",
      "[20200116T195050] Epock 327 / 1000 loss: 36.937970055474175\n",
      "[20200116T195059] Epock 328 / 1000 loss: 35.70935567220052\n",
      "[20200116T195108] Epock 329 / 1000 loss: 35.137569380395206\n",
      "[20200116T195117] Epock 330 / 1000 loss: 34.95490036481692\n",
      "[20200116T195126] Epock 331 / 1000 loss: 34.58126065760483\n",
      "[20200116T195135] Epock 332 / 1000 loss: 35.18895514217424\n",
      "[20200116T195144] Epock 333 / 1000 loss: 35.239443955598055\n",
      "[20200116T195153] Epock 334 / 1000 loss: 35.976292080349396\n",
      "[20200116T195202] Epock 335 / 1000 loss: 35.24716033464597\n",
      "[20200116T195211] Epock 336 / 1000 loss: 34.430804900181144\n",
      "[20200116T195221] Epock 337 / 1000 loss: 37.108353508843315\n",
      "[20200116T195230] Epock 338 / 1000 loss: 36.007808025972345\n",
      "[20200116T195239] Epock 339 / 1000 loss: 38.411875006593306\n",
      "[20200116T195248] Epock 340 / 1000 loss: 37.031971048425746\n",
      "[20200116T195258] Epock 341 / 1000 loss: 36.41857705292878\n",
      "[20200116T195307] Epock 342 / 1000 loss: 35.93856081550504\n",
      "[20200116T195316] Epock 343 / 1000 loss: 35.74339358011881\n",
      "[20200116T195325] Epock 344 / 1000 loss: 35.627307232515314\n",
      "[20200116T195334] Epock 345 / 1000 loss: 34.2714239285316\n",
      "[20200116T195344] Epock 346 / 1000 loss: 34.10134901823821\n",
      "[20200116T195353] Epock 347 / 1000 loss: 34.33521070598084\n",
      "[20200116T195402] Epock 348 / 1000 loss: 34.483222207905335\n",
      "[20200116T195411] Epock 349 / 1000 loss: 34.19316487253448\n",
      "[20200116T195420] Epock 350 / 1000 loss: 34.62568692807798\n",
      "[20200116T195428] Epock 351 / 1000 loss: 33.299409560215324\n",
      "[20200116T195437] Epock 352 / 1000 loss: 33.741727899622035\n",
      "[20200116T195446] Epock 353 / 1000 loss: 33.937213991895135\n",
      "[20200116T195455] Epock 354 / 1000 loss: 33.60329839918349\n",
      "[20200116T195504] Epock 355 / 1000 loss: 33.048746485769016\n",
      "[20200116T195514] Epock 356 / 1000 loss: 33.41736812356078\n",
      "[20200116T195523] Epock 357 / 1000 loss: 34.03392031163345\n",
      "[20200116T195532] Epock 358 / 1000 loss: 34.27438119017047\n",
      "[20200116T195541] Epock 359 / 1000 loss: 32.837202472451295\n",
      "[20200116T195550] Epock 360 / 1000 loss: 33.7232007627134\n",
      "[20200116T195559] Epock 361 / 1000 loss: 33.51828897735219\n",
      "[20200116T195609] Epock 362 / 1000 loss: 34.63799921671549\n"
     ]
    }
   ],
   "source": [
    "total_epoch = 1000\n",
    "\n",
    "for e in tqdm_notebook(range(total_epoch), total=total_epoch, desc='Epoch'):\n",
    "    loss = trainer.train(train_loader)\n",
    "    \n",
    "    ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "    print(f'[{ts}] Epock {e} / {total_epoch} loss: {loss}')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-16T10:56:14.644Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'checkpoint.pt.{loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
