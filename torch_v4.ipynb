{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:33.773324Z",
     "start_time": "2020-01-15T12:56:32.595055Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[1]:\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "import glob\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import gc\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import json\n",
    "from typing import NamedTuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "print(torch.__version__)\n",
    "# from tools import eval_summary, save_feature_importance, merge_preds\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:33.776120Z",
     "start_time": "2020-01-15T12:56:33.774264Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_num_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:33.789409Z",
     "start_time": "2020-01-15T12:56:33.777182Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:45.586495Z",
     "start_time": "2020-01-15T12:56:33.790245Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('input/train.csv', dtype=np.float32)\n",
    "df_test = pd.read_csv('input/test.csv', dtype=np.float32)\n",
    "print(df_train.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:45.589981Z",
     "start_time": "2020-01-15T12:56:45.587215Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_cols = [c for c in df_train.columns if 'layer_' in c]\n",
    "fea_cols = [c for c in df_train.columns if c not in layer_cols]\n",
    "\n",
    "len(fea_cols), len(layer_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:45.597693Z",
     "start_time": "2020-01-15T12:56:45.590660Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:45.604391Z",
     "start_time": "2020-01-15T12:56:45.598273Z"
    }
   },
   "outputs": [],
   "source": [
    "class DNN1Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout_probability=0.3):\n",
    "        super().__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.layer_1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size + 1, input_size), relu, \n",
    "            torch.nn.Linear(input_size, input_size), relu, \n",
    "            torch.nn.Linear(input_size, input_size), relu, \n",
    "        )\n",
    "        self.layer_2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size + 1, input_size), relu, \n",
    "            torch.nn.Linear(input_size, input_size), relu, \n",
    "            torch.nn.Linear(input_size, input_size), relu, \n",
    "        )\n",
    "        self.layer_3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size + 1, input_size), relu, \n",
    "            torch.nn.Linear(input_size, input_size), relu, \n",
    "            torch.nn.Linear(input_size, input_size), relu, \n",
    "        )\n",
    "        self.layer_4 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size + 1, input_size), relu, \n",
    "            torch.nn.Linear(input_size, input_size), relu, \n",
    "            torch.nn.Linear(input_size, input_size),\n",
    "        )\n",
    "    def forward(self, x_fea, x1, x2, x3, x4):\n",
    "        out_layer_1 = self.layer_1(torch.cat([x_fea, x1], axis=1))\n",
    "        out_layer_2 = self.layer_2(torch.cat([out_layer_1, x2], axis=1))\n",
    "        out_layer_3 = self.layer_3(torch.cat([out_layer_2, x3], axis=1))\n",
    "        out_layer_4 = self.layer_4(torch.cat([out_layer_3, x4], axis=1))\n",
    "        \n",
    "        return out_layer_4\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:57:16.154252Z",
     "start_time": "2020-01-14T00:57:16.152105Z"
    }
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:45.611679Z",
     "start_time": "2020-01-15T12:56:45.604994Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:45.617118Z",
     "start_time": "2020-01-15T12:56:45.612695Z"
    }
   },
   "outputs": [],
   "source": [
    "class SemiDataset(Dataset):\n",
    "    def __init__(self, df, fea_cols, layer_cols):        \n",
    "        self.fea_cols = fea_cols\n",
    "        self.X_fea = df[fea_cols].values\n",
    "        self.X_layers = []\n",
    "        for c in layer_cols:\n",
    "            self.X_layers.append(df_model[[c]].values)\n",
    "        self.y = np.zeros((len(self.X_fea), len(self.fea_cols)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_fea)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        layers = [x[idx] for x in self.X_layers]\n",
    "#         return self.X_fea[idx].astype(np.float32), layers, self.y[idx].astype(np.float32)\n",
    "        return self.y[idx].astype(np.float32), layers, self.X_fea[idx].astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:47.016365Z",
     "start_time": "2020-01-15T12:56:45.617791Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print(model_ts)\n",
    "\n",
    "print(f'fea_size {len(fea_cols)} layer_cols {layer_cols}')\n",
    "\n",
    "model = DNN1Model(input_size=len(fea_cols), dropout_probability=0.5).to(device)\n",
    "    \n",
    "criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler = StepLR(optimizer, step_size=400, gamma=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:56:47.108239Z",
     "start_time": "2020-01-15T12:56:47.017358Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SemiDataset(df_model, fea_cols, layer_cols)\n",
    "\n",
    "train_loader_params = {\n",
    "    'dataset' : train_dataset,\n",
    "    'batch_size' : len(train_dataset) // 4,\n",
    "    'shuffle' : True,\n",
    "    'num_workers' : 4,\n",
    "    'drop_last' : False,\n",
    "}\n",
    "train_loader = DataLoader(**train_loader_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:12:16.802242Z",
     "start_time": "2020-01-15T12:56:47.109178Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_epoch = 100\n",
    "model.train()\n",
    "\n",
    "for e in tqdm_notebook(range(total_epoch), total=total_epoch, desc='Epoch'):\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        X_fea, X_layers, y_batch = data\n",
    "        \n",
    "        y_pred = model(X_fea.to(device), *[x.to(device) for x in X_layers])\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.to(device))\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #     scheduler.step()\n",
    "    \n",
    "    ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "    print(f'[{ts}] Epock {e} / {total_epoch} loss: {total_loss / len(train_loader)}')\n",
    "    \n",
    "    if e % 1000 == 0:\n",
    "        torch.save(model.state_dict(), 'checkpoint_1nn.pt')\n",
    "\n",
    "torch.save(model.state_dict(), 'checkpoint_1nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:12:16.804743Z",
     "start_time": "2020-01-15T13:12:16.803223Z"
    }
   },
   "outputs": [],
   "source": [
    "# self.X_fea = df[fea_cols].values\n",
    "# self.X_layers = []\n",
    "# for c in layer_cols:\n",
    "#     self.X_layers.append(df_model[[c]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:12:16.819939Z",
     "start_time": "2020-01-15T13:12:16.805487Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = torch.Tensor(df_model.loc[:1, fea_cols].values)\n",
    "X_test_layers = []\n",
    "for c in layer_cols:\n",
    "    X_test_layers.append(torch.Tensor(df_model.loc[:1, [c]].values))\n",
    "X_test_layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:12:16.823619Z",
     "start_time": "2020-01-15T13:12:16.820827Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = torch.Tensor(np.zeros(len(fea_cols)).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:12:16.829688Z",
     "start_time": "2020-01-15T13:12:16.824384Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:12:16.835225Z",
     "start_time": "2020-01-15T13:12:16.830440Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model(X_test.to(device), *[x.to(device) for x in X_test_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:12:16.841189Z",
     "start_time": "2020-01-15T13:12:16.835976Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion(y_pred[0], y_test.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:12:16.845987Z",
     "start_time": "2020-01-15T13:12:16.841928Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion(y_pred[1], y_test.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
