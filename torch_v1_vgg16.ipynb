{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:24:35.894927Z",
     "start_time": "2020-01-16T06:24:35.113531Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[1]:\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "import glob\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import gc\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import json\n",
    "from typing import NamedTuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "print(torch.__version__)\n",
    "# from tools import eval_summary, save_feature_importance, merge_preds\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:24:35.899097Z",
     "start_time": "2020-01-16T06:24:35.896324Z"
    }
   },
   "outputs": [],
   "source": [
    "# In[2]:\n",
    "torch.set_num_threads(8)\n",
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:24:47.475131Z",
     "start_time": "2020-01-16T06:24:35.900396Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('input/train.csv', dtype=np.float32)\n",
    "df_test = pd.read_csv('input/test.csv', dtype=np.float32)\n",
    "print(df_train.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:24:47.478613Z",
     "start_time": "2020-01-16T06:24:47.475895Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_cols = [c for c in df_train.columns if 'layer_' in c]\n",
    "fea_cols = [c for c in df_train.columns if c not in layer_cols]\n",
    "\n",
    "len(fea_cols), len(layer_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:24:47.499223Z",
     "start_time": "2020-01-16T06:24:47.479365Z"
    }
   },
   "outputs": [],
   "source": [
    "cond = (df_train['layer_2'] == 10) & (df_train['layer_3'] == 10) & (df_train['layer_4'] == 10)\n",
    "df_model = df_train[cond]\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:25:04.745975Z",
     "start_time": "2020-01-16T06:25:04.741769Z"
    }
   },
   "outputs": [],
   "source": [
    "# size = 48\n",
    "W = 226 # input_volume_size\n",
    "F = 3  # kernel_size\n",
    "S = 1   # strides\n",
    "P = 1\n",
    "# padding_size\n",
    "\n",
    "size = (W - F + 2*P) / S + 1\n",
    "size\n",
    "# ((size - 1) * S) - 2*P + F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:25:08.698593Z",
     "start_time": "2020-01-16T06:25:08.644872Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_probability=0.5):\n",
    "        super().__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(1, 12, 3, stride=1, padding=1), torch.nn.BatchNorm1d(12), relu,\n",
    "            torch.nn.Conv1d(12, 12, 3, stride=1, padding=1), torch.nn.BatchNorm1d(12), relu,\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.Conv1d(12, 24, 3, stride=1, padding=1), torch.nn.BatchNorm1d(24), relu,\n",
    "            torch.nn.Conv1d(24, 24, 3, stride=1, padding=1), torch.nn.BatchNorm1d(24), relu,\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.Conv1d(24, 48, 3, stride=1, padding=1), torch.nn.BatchNorm1d(48), relu,\n",
    "            torch.nn.Conv1d(48, 48, 3, stride=1, padding=1), torch.nn.BatchNorm1d(48), relu,\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.Conv1d(48, 96, 3, stride=1, padding=1), torch.nn.BatchNorm1d(96), relu,\n",
    "            torch.nn.Conv1d(96, 96, 3, stride=1, padding=1), torch.nn.BatchNorm1d(96), relu,\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.Conv1d(96, 96, 3, stride=1, padding=1), torch.nn.BatchNorm1d(96), relu,\n",
    "            torch.nn.Conv1d(96, 96, 3, stride=1, padding=1), torch.nn.BatchNorm1d(96), relu,\n",
    "            torch.nn.MaxPool1d(2),\n",
    "        )\n",
    "            \n",
    "        self.clf = torch.nn.Sequential(\n",
    "            torch.nn.Linear(672, 512), relu, dropout, #torch.nn.BatchNorm1d(128), dropout,\n",
    "            torch.nn.Linear(512, 512), relu, dropout, \n",
    "            torch.nn.Linear(512, 4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out = self.cnn(x)\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]: #24, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.clf(out)\n",
    "        return out\n",
    "\n",
    "#         return self.model(x)\n",
    "    \n",
    "class SemiDataset(Dataset):\n",
    "    def __init__(self, df, fea_cols, y_cols):        \n",
    "        self.X = df[fea_cols].values\n",
    "        self.y = df[y_cols].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].astype(np.float32), self.y[idx].astype(np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:25:09.864549Z",
     "start_time": "2020-01-16T06:25:09.852003Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, criterion, optimizer, scheduler, device):\n",
    "        self.device = device\n",
    "        self.model = model#.to(self.device)\n",
    "        self.criterion = criterion#.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        print(self.model.train())\n",
    "        pass\n",
    "    \n",
    "    def train(self, data_loader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "#         print('train_loader', len(train_loader))\n",
    "        for data in data_loader:\n",
    "            X_batch, y_batch = data\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            \n",
    "            y_pred = self.model(X_batch)\n",
    "#             print(y_pred, y_batch)\n",
    "            \n",
    "#             y_pred = torch.round(y_pred)    \n",
    "            loss = self.criterion(y_pred, y_batch)\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "        \n",
    "#         print(f'total_loss {total_loss / len(data_loader)}')\n",
    "        return total_loss / len(data_loader)\n",
    "    \n",
    "    def eval(self, data_loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "#         print('valid_loader', len(valid_loader))\n",
    "        for data in data_loader:\n",
    "            X_batch, y_batch = data\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_pred = self.model(X_batch)\n",
    "                loss = self.criterion(y_pred, y_batch)\n",
    "                \n",
    "                y_pred = torch.round(y_pred)\n",
    "                y_pred = y_pred / 10\n",
    "                y_pred = torch.round(y_pred)\n",
    "                y_pred = y_pred * 10\n",
    "                \n",
    "                print(y_pred, y_batch)\n",
    "#                 print(loss.item())\n",
    "                total_loss = total_loss + loss.item()\n",
    "#         print(f'total_loss {total_loss / len(data_loader)}')\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def save(self, model_path='checkpoint.pt'):\n",
    "        torch.save(self.model.state_dict(), 'checkpoint.pt')\n",
    "        return\n",
    "    \n",
    "    def load(self, model_path='checkpoint.pt'):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T00:57:16.154252Z",
     "start_time": "2020-01-14T00:57:16.152105Z"
    }
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:25:12.321126Z",
     "start_time": "2020-01-16T06:25:10.893388Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print(model_ts)\n",
    "\n",
    "batch_size = 10000\n",
    "num_workers = 0\n",
    "\n",
    "print(f'batch_size {batch_size} num_workers {num_workers}')\n",
    "print(f'fea_size {len(fea_cols)} layer_cols {layer_cols}')\n",
    "\n",
    "\n",
    "# model = DNNModel(input_size=len(fea_cols), dropout_probability=0.5).to(device)\n",
    "model = CNNModel(dropout_probability=0.5).to(device)\n",
    "\n",
    "    \n",
    "criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "# criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, )\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=200, gamma=0.9)\n",
    "\n",
    "trainer = Trainer(model, criterion, optimizer, scheduler, device)\n",
    "# trainer.load()\n",
    "\n",
    "# train_dataset = SemiDataset(df_model[fea_cols + layer_cols], fea_cols, layer_cols)\n",
    "train_dataset = SemiDataset(df_model[fea_cols + layer_cols], fea_cols, layer_cols)\n",
    "\n",
    "train_loader_params = {\n",
    "    'dataset' : train_dataset,\n",
    "    'batch_size' : batch_size,\n",
    "    'shuffle' : False,\n",
    "    'num_workers' : num_workers,\n",
    "    'drop_last' : False,\n",
    "}\n",
    "train_loader = DataLoader(**train_loader_params)\n",
    "\n",
    "print(f'train_loader {len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:25:12.323764Z",
     "start_time": "2020-01-16T06:25:12.322080Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:26:03.652054Z",
     "start_time": "2020-01-16T06:25:12.616767Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_epoch = 5000\n",
    "\n",
    "for e in tqdm_notebook(range(total_epoch), total=total_epoch, desc='Epoch'):\n",
    "    loss = trainer.train(train_loader)\n",
    "    \n",
    "    if e % 100 == 0:\n",
    "        ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'[{ts}] Epock {e} / {total_epoch}\\tlr:{lr}\\tloss: {loss}')\n",
    "    \n",
    "torch.save(model.state_dict(), 'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:26:06.534380Z",
     "start_time": "2020-01-16T06:26:06.514525Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(model, criterion, optimizer, None, device)\n",
    "loss = trainer.eval(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:26:07.060081Z",
     "start_time": "2020-01-16T06:26:07.057181Z"
    }
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
